# RAG Offline Soberano â€” v1.0

RAG local con FastAPI + FAISS + llama.cpp (LLM GGUF) + sentence-transformers (embeddings).

## âœ¨ CaracterÃ­sticas

- ğŸ”’ **100% Local y Privado**: Sin conexiÃ³n a internet, tus datos nunca salen de tu mÃ¡quina
- ğŸš€ **RecuperaciÃ³n HÃ­brida**: FAISS (vectorial) + BM25 (lÃ©xico) + Cross-Encoder reranking
- ğŸ§  **LLM Local**: Mistral 7B con llama.cpp (GGUF)
- ğŸ“„ **Multi-formato**: PDF, Markdown, TXT
- ğŸ¯ **BÃºsqueda Avanzada**: Filtrado por documento, navegaciÃ³n a pÃ¡ginas especÃ­ficas
- âš¡ **Optimizado**: CachÃ© de queries, deduplicaciÃ³n de chunks, chunking semÃ¡ntico
- ğŸ”§ **Production-Ready**: Health checks, rate limiting, logging estructurado, validaciones

## ğŸ†• Nuevas CaracterÃ­sticas (v1.0)

- âœ… **ConfiguraciÃ³n con Variables de Entorno** (.env)
- âœ… **Validaciones Pydantic** con Field validators
- âœ… **Logging Estructurado** (JSON opcional)
- âœ… **Rate Limiting** (slowapi)
- âœ… **CachÃ© de Respuestas** (TTL configurable)
- âœ… **Health Checks** (`/health`, `/stats`)
- âœ… **CORS Configurable** (no mÃ¡s `allow_origins=["*"]`)
- âœ… **ValidaciÃ³n de Archivos** (tamaÃ±o, tipo)
- âœ… **Tests Unitarios** (pytest + coverage)
- âœ… **Docker Compose** para desarrollo

## ğŸ“‹ Requisitos

- Python 3.10+
- CPU x86_64 con AVX2 (recomendado)
- RAM 16 GB (mÃ­nimo 8 GB)
- **Sin GPU**: OK (modelo 7B cuantizado Q4_K_M)

## ğŸš€ InstalaciÃ³n RÃ¡pida

### 1. Clonar repositorio
```bash
git clone <url-repo>
cd proyectoRAG
```

### 2. Backend

```bash
cd backend

# Crear entorno virtual
python -m venv .venv

# Activar (Windows PowerShell)
.venv\Scripts\activate
# Activar (Linux/Mac)
source .venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Copiar y configurar variables de entorno
cp .env.example .env
# Editar .env con tu configuraciÃ³n

# Descargar modelo LLM (ejemplo)
# Descarga mistral-7b-instruct-q4_k_m.gguf desde HuggingFace
# y colÃ³calo en: backend/data/models/llm/
```

### 3. Frontend

```bash
cd ../frontend

# Instalar dependencias
npm install

# Copiar PDF.js assets
npm run pdfjs:copy
```

## ğŸƒâ€â™‚ï¸ EjecuciÃ³n

### Desarrollo

**Backend** (con hot-reload):
```bash
cd backend
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

**Frontend**:
```bash
cd frontend
npm run dev
```

### Con Docker Compose

```bash
# Desde la raÃ­z del proyecto
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener
docker-compose down
```

## ğŸ“¡ API Endpoints

### Principales

- `POST /ingest` - Subir y indexar documentos
- `POST /ingest/all` - Reindexar todos los documentos
- `POST /ask` - Hacer una pregunta al sistema RAG
- `GET /sources` - Listar documentos disponibles

### Health & Monitoring

- `GET /health` - Health check (status, LLM loaded, chunks count)
- `GET /stats` - EstadÃ­sticas del sistema (docs, chunks, embedder)
- `GET /cache/stats` - EstadÃ­sticas del cachÃ©
- `POST /cache/clear` - Limpiar cachÃ©

### Debug

- `GET /debug/paths` - Ver rutas configuradas
- `GET /debug/pdfjs` - Verificar PDF.js

## âš™ï¸ ConfiguraciÃ³n (.env)

```bash
# Modelos
EMBEDDING_MODEL_ID=intfloat/multilingual-e5-base
LLM_MODEL_PATH=data/models/llm/mistral-7b-instruct-q4_k_m.gguf

# RAG Parameters
CHUNK_SIZE=900
CHUNK_OVERLAP=150
TOP_K=4

# llama.cpp
N_CTX=1024
N_THREADS=4
TEMPERATURE=0.2
MAX_TOKENS=256

# Seguridad
ALLOWED_ORIGINS=http://localhost:5173,http://127.0.0.1:5173
MAX_FILE_SIZE_MB=50
RATE_LIMIT_PER_MINUTE=10

# Cache
ENABLE_CACHE=true
CACHE_TTL_SECONDS=300

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
```

## ğŸ§ª Testing

```bash
cd backend

# Ejecutar todos los tests
pytest

# Con coverage
pytest --cov=backend --cov-report=html

# Ver reporte HTML
# Abre: htmlcov/index.html

# Tests especÃ­ficos
pytest tests/test_models.py
pytest tests/test_cache.py
pytest tests/test_api.py
```

## ğŸ“Š Arquitectura

```
proyectoRAG/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # FastAPI app principal
â”‚   â”œâ”€â”€ config.py           # ConfiguraciÃ³n con pydantic-settings
â”‚   â”œâ”€â”€ models.py           # Modelos Pydantic
â”‚   â”œâ”€â”€ rag.py              # LÃ³gica RAG (FAISS + BM25 + rerank)
â”‚   â”œâ”€â”€ ingest.py           # Ingesta y chunking
â”‚   â”œâ”€â”€ enhanced_retrieval.py  # Embeddings y cross-encoder
â”‚   â”œâ”€â”€ logger.py           # Sistema de logging
â”‚   â”œâ”€â”€ cache.py            # Sistema de cachÃ©
â”‚   â”œâ”€â”€ .env.example        # Template de configuraciÃ³n
â”‚   â”œâ”€â”€ requirements.txt    # Dependencias Python
â”‚   â”œâ”€â”€ pyproject.toml      # Config de pytest
â”‚   â”œâ”€â”€ tests/              # Tests unitarios
â”‚   â”‚   â”œâ”€â”€ test_models.py
â”‚   â”‚   â”œâ”€â”€ test_cache.py
â”‚   â”‚   â””â”€â”€ test_api.py
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ docs/           # Documentos a indexar
â”‚       â”œâ”€â”€ store/          # Ãndice FAISS + metadata
â”‚       â”œâ”€â”€ models/         # Modelos descargados
â”‚       â””â”€â”€ logs/           # Archivos de log
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Componentes React
â”‚   â”‚   â”œâ”€â”€ lib/            # Utilidades (API, storage, PDF)
â”‚   â”‚   â””â”€â”€ styles/         # CSS global
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml      # Compose para desarrollo
â””â”€â”€ README.md
```

## ğŸ”§ Troubleshooting

### Error: "LLM no encontrado"
- Verifica que `LLM_MODEL_PATH` en `.env` apunte al archivo GGUF correcto
- Descarga un modelo compatible desde HuggingFace

### Error: "Import pydantic_settings not found"
```bash
pip install pydantic-settings
```

### Error: Rate limit exceeded
- Ajusta `RATE_LIMIT_PER_MINUTE` en `.env`
- O desactiva temporalmente el rate limiting

### Puerto 8000 ya en uso
```bash
# Cambiar puerto
uvicorn app:app --port 8001
```

## ğŸ“ˆ Performance Tips

1. **Aumentar N_CTX**: Si tienes RAM suficiente, aumenta a 2048 o 4096
2. **Ajustar N_THREADS**: Iguala al nÃºmero de cores de tu CPU
3. **Habilitar CachÃ©**: `ENABLE_CACHE=true` reduce latencia en queries repetidas
4. **Chunk Size**: Ajusta `CHUNK_SIZE` segÃºn tus documentos (mÃ¡s pequeÃ±o = mÃ¡s preciso, mÃ¡s grande = mÃ¡s contexto)

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -am 'Agregar mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

## ğŸ“ Licencia

MIT License - ver archivo LICENSE para detalles

## ğŸ™ Agradecimientos

- [FastAPI](https://fastapi.tiangolo.com/)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [sentence-transformers](https://www.sbert.net/)
- [FAISS](https://github.com/facebookresearch/faiss)
- Comunidad de Software Libre â¤ï¸

---

**Hecho con â¤ï¸ y Software Libre Â· Funciona 100% local**
